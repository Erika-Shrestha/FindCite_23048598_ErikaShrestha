{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31b1nbsSoNJj"
   },
   "source": [
    "<font color=\"#006400\" face=\"sans-serif\" size=\"7\">\n",
    "<b>Erika Shrestha</b>\n",
    "</font>\n",
    "<BR>\n",
    "<font color=\"#006400\" face=\"sans-serif\" size=\"4.5\">\n",
    "<b>London Met ID: 23048598</b>\n",
    "</font>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_3tsheSoWEc"
   },
   "source": [
    "<b>FindCite is a text classification model that automatically classify citations in scientific research papers according to their purpose. This project aims to compare baseline model (Logistic Regression) and advanced model (SciBERT) to validate their adaptability and limitations.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRg89vw7pdcu"
   },
   "outputs": [],
   "source": [
    "#INSTALL necessary librabries that are not by-default stored in golab\n",
    "#!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SltrqgQiqBCd"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpV_k7Jypt43"
   },
   "source": [
    "# **TEMPORARY DATA LOAD**\n",
    "This notebook is designed to be fully reproducible in Google Colab.\n",
    "Please ensure the setup cells (dataset download and folder creation) are run sequentially before executing the rest of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2z6KKSQp8oN"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pVh9OnatqJpT"
   },
   "outputs": [],
   "source": [
    "#CREATE an empty folder in colab temporary files\n",
    "!mkdir -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pfk7DvO8qKSG",
    "outputId": "2a889724-d2f2-4aff-cc6a-acf3652dfca8"
   },
   "outputs": [],
   "source": [
    "#CONNECT the data files which contains train, test and validation\n",
    "!wget https://ai2-s2-research.s3-us-west-2.amazonaws.com/scicite/scicite.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gEMPVG8fqMw0",
    "outputId": "08eb58e2-39ac-47e9-b99b-4efd29b9fac1"
   },
   "outputs": [],
   "source": [
    "#EXTRACT the connected taz file\n",
    "!tar -xvzf scicite.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zras9TKcqSAA"
   },
   "outputs": [],
   "source": [
    "#MOVE the required json files into the created data folder\n",
    "!mv scicite/train.jsonl scicite/dev.jsonl scicite/test.jsonl data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcZrT9BhqxXr"
   },
   "source": [
    "-------\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1wRrKGJqilr"
   },
   "source": [
    "# **Let's Get Started**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X7iL95J3qUNy"
   },
   "outputs": [],
   "source": [
    "#IMPORT all the necessary libraries used in the project\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from wordcloud import WordCloud\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "import tensorflow as tf\n",
    "from scipy.special import softmax\n",
    "from tf_keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, precision_recall_curve, roc_curve, auc\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "import joblib\n",
    "from google.colab import files\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5-RG6VIl9OH"
   },
   "source": [
    "# **HELPER METHODS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcJUSRZ9wbRB"
   },
   "outputs": [],
   "source": [
    "#FUNCTION to plot word cloud\n",
    "def plot_wordcloud_per_class(X_texts, y_labels, title=\"Word Cloud\"):\n",
    "  classes = sorted(set(y_labels))\n",
    "  fig, axes = plt.subplots(1, len(classes), figsize=(18, 6))\n",
    "\n",
    "  for ax, cls in zip(axes, classes):\n",
    "      text = \" \".join(X_texts[y_labels == cls])\n",
    "\n",
    "      wc = WordCloud(\n",
    "          background_color=\"white\",\n",
    "          max_words=200,\n",
    "          width=800,\n",
    "          height=400\n",
    "      )\n",
    "\n",
    "      wc.generate(text)\n",
    "      ax.imshow(wc, interpolation=\"bilinear\")\n",
    "      ax.set_title(f\"{title} ‚Äì Class {cls}\")\n",
    "      ax.axis(\"off\")\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0_7-UyZ3k9H6"
   },
   "outputs": [],
   "source": [
    "#FUNCTION to plot learning curve to check overfitting and underfitting\n",
    "def plot_learning_curve(model, X, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 5), scoring='f1_macro', title=\"Learning Curve\"):\n",
    "\n",
    "  train_sizes, train_scores, val_scores = learning_curve(\n",
    "        model, X, y, cv=cv, train_sizes=train_sizes, scoring=scoring, n_jobs=-1\n",
    "    )\n",
    "\n",
    "  plt.plot(train_sizes, train_scores.mean(axis=1), marker='o', color='blue', label='Training Score')\n",
    "  plt.plot(train_sizes, val_scores.mean(axis=1), marker='s', color='purple', label='Validation Score')\n",
    "  plt.xlabel('Training Size')\n",
    "  plt.ylabel('F1 Score')\n",
    "  plt.title(f'{title} Learning Curve')\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtvEQhelqRtc"
   },
   "outputs": [],
   "source": [
    "#FUNCTION to plot confusion matrix to check model predictions accuracy\n",
    "def plot_confusion_matrix(y_true, y_pred, labels, title=\"Confusion Matrix\", cmap='Blues'):\n",
    "\n",
    "  class_names = ['Background', 'Method', 'Result']\n",
    "\n",
    "  cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "\n",
    "  disp.plot(cmap=cmap, xticks_rotation=45)\n",
    "  plt.title(title)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2ezD8aFmlyo"
   },
   "outputs": [],
   "source": [
    "#FUNCTION to plot PR curve to check model actual performance and not just accuracy\n",
    "def plot_precision_recall_curve(y_true, y_scores, title=\"Precision-Recall Curve\"):\n",
    "\n",
    "    classes = np.unique(y_test)\n",
    "    y_test_bin = label_binarize(y_test, classes=classes)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    colors = ['purple', 'blue', 'yellow']\n",
    "\n",
    "    for i, cls in enumerate(classes):\n",
    "        precision, recall, _ = precision_recall_curve(y_test_bin[:, i], y_scores[:, i])\n",
    "        auc_score = auc(recall, precision)\n",
    "        plt.plot(recall, precision, color=colors[i], label=f'Class {cls} (AUC={auc_score:.2f})')\n",
    "\n",
    "    plt.xlabel(\"recall\")\n",
    "    plt.ylabel(\"precision\")\n",
    "    plt.title(f'{title} PR Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "No2TdJVG8-kD"
   },
   "outputs": [],
   "source": [
    "#FUNCTION to plot ROC-AUC curve to check one vs rest\n",
    "def plot_roc_auc_curve(y_true, y_scores, class_names=None, title=\"ROC-AUC Curve\"):\n",
    "    classes = np.unique(y_true)\n",
    "    y_bin = label_binarize(y_true, classes=classes)\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    colors = ['purple', 'blue', 'yellow']\n",
    "\n",
    "    for i, cls in enumerate(classes):\n",
    "        fpr, tpr, _ = roc_curve(y_bin[:, i], y_scores[:, i])\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, color=colors[i], label=f'Class {class_names[i]} (AUC={auc_score:.2f})')\n",
    "\n",
    "    # Random classifier baseline\n",
    "    plt.plot([0,1], [0,1], 'k--', label='Random')\n",
    "\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(False)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mTIWvMdP_bwe"
   },
   "outputs": [],
   "source": [
    "#FUNCTION to plot scibert history behavior based on metrics: loss and accuracy\n",
    "def plot_history(history, metric='loss', title=\"Training vs Validation\"):\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(history.history[metric], label=f'Train {metric}', marker='o', color='blue')\n",
    "    plt.plot(history.history['val_' + metric], label=f'Val {metric}', marker='s', color='purple')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(f'{title} {metric}')\n",
    "    plt.legend()\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jb2Ms1ZumI9-"
   },
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjEuf6W8rCv0"
   },
   "source": [
    "# **EXPLORATORY DATA ANALYSIS (EDA)** üìä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dD_u-6VqqhLN"
   },
   "source": [
    "**The original Scicite dataset provides separate train, development, and test splits. For understanding the characteristics of the datasets, the train, test and development sets were concatenated to form a larger labeled dataset while test sets is carefully examined due to absence of 1 column (label_confidence)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "u3_CSKinrJHM",
    "outputId": "50a35afd-4ab8-4dab-c400-59cb8eb9dc96"
   },
   "outputs": [],
   "source": [
    "#IMPORT training data from data Folder\n",
    "train_df = pd.read_json('data/train.jsonl', lines=True)\n",
    "#head() shows only 5 documents by default\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "T6KUL7v_rbDh",
    "outputId": "4a0b2ac1-4347-4554-a964-307129922b41"
   },
   "outputs": [],
   "source": [
    "#IMPORT testing data from data Folder\n",
    "test_df = pd.read_json('data/test.jsonl', lines=True)\n",
    "#head() shows only 5 documents by default\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "i_f1xf3irej6",
    "outputId": "e7f750b2-c3db-4e50-e0f4-ff9a2ed53c25"
   },
   "outputs": [],
   "source": [
    "#IMPORT validation data from data Folder\n",
    "val_df = pd.read_json('data/dev.jsonl', lines=True)\n",
    "#head() shows only 5 documents by default\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b68ApEQXrgVy",
    "outputId": "39e8d0a7-3767-4a18-ba2f-31c02d69265e"
   },
   "outputs": [],
   "source": [
    "#CONCATINATE train and validation sets\n",
    "explore_df = pd.concat([train_df, val_df, test_df])\n",
    "explore_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Db_ie_VFriXj"
   },
   "source": [
    "**The individual dataset splits were first concatenated into a single dataframe with a shape of (11020 x 15) to facilitate unified preprocessing and exploratory data analysis (EDA).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKHWLe2NubeX"
   },
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LA62HO08tSRI"
   },
   "source": [
    "# **Data Quality Check** ‚òëÔ∏è\n",
    "\n",
    "1.   Missing Values Check\n",
    "2.   Data Type Consistency\n",
    "3.   Duplication Check\n",
    "4.   Label Distribution\n",
    "5.   Text Length Distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fG4ui3HhucFB"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCsZGsO1wS2S"
   },
   "source": [
    "#####**1. Missing Values Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "frNmx8BgwWaU",
    "outputId": "5bc73d75-190a-4cff-c82f-4bc4a8b34f66"
   },
   "outputs": [],
   "source": [
    "#CHECKS the missing values of all the columns in the findcite_df\n",
    "#logarithm scaling is used for y-axis to visualize columns with large gap in missing values\n",
    "missing_counts = explore_df.isnull().sum()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(missing_counts.index, missing_counts.values, color='#E0AAFF')\n",
    "plt.yscale('log')\n",
    "plt.title('Missing Values Per Column', fontweight='bold')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Missing Values')\n",
    "plt.xlabel('Columns')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "p39dYl390oNY",
    "outputId": "c9f30c5f-1871-4332-ef14-41913e5b7bd8"
   },
   "outputs": [],
   "source": [
    "#CHECKS whether there is presence of high missing values (case = missing_values > 50%)\n",
    "total_rows = len(explore_df)\n",
    "missing_percent_per_columns = ((missing_counts / total_rows) * 100).round(1)\n",
    "missing_percent_per_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjXrtayFwck-"
   },
   "source": [
    "**Eight columns have no missing values, which means the core data is complete and reliable. A few columns such as source, citeStart, citeEnd, and sectionName have only a small number of missing entries so they are not a major issue.**\n",
    "\n",
    "**However, the columns label_confidence, label2, and label2_confidence have a very large number of missing values. This means secondary labels and their confidence scores are mostly unavailable and may not be useful to perform multi label classification.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UeELFrZu016i"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NaBvFjRz0Czc"
   },
   "source": [
    "#####**2. Data Type Consistency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdOKyind1Htp",
    "outputId": "f4871da1-218b-459d-92b9-7bf80142e8a0"
   },
   "outputs": [],
   "source": [
    "#CHECKS data types for each dataframes\n",
    "print(f\"\\033[1mTrain sets data types:\\033[0m\\n{train_df.dtypes}\\n\")\n",
    "print(f\"\\033[1mValidation sets data types:\\033[0m\\n{val_df.dtypes}\\n\")\n",
    "print(f\"\\033[1mTest sets data types:\\033[0m\\n{test_df.dtypes}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1jZNy2R1o3a"
   },
   "source": [
    "**According to the information, All the data types are consistent.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttptswtT1eKA"
   },
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WyHP7e11c9t"
   },
   "source": [
    "#####**3. Duplication Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PiOregu21_Fb",
    "outputId": "033341ad-3177-4174-f88a-b07b1df2c44f"
   },
   "outputs": [],
   "source": [
    "#SHOWS all the duplicate document in the dataframe through keep=false\n",
    "duplicates = explore_df[explore_df.duplicated(keep=False)]\n",
    "print(duplicates.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8i1HNgomCsdw"
   },
   "source": [
    "The **4378** and **503** rows were found to have same entries for every columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtNU-E7OCzgd"
   },
   "outputs": [],
   "source": [
    "#REMOVES the duplicated document but keeps the first occurrence\n",
    "explore_df = explore_df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5W1Cp7RBDSeB",
    "outputId": "3c0b343a-b842-40d9-a396-818634ec27c8"
   },
   "outputs": [],
   "source": [
    "#CROSS CHECKING the removal of duplicates\n",
    "explore_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faUPqP9hEQf3"
   },
   "source": [
    "**After finding a duplicate document in the dataframe, we remove but keep the first occurring document.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFdp6GYCFOGC"
   },
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lR9g7bneFQLB"
   },
   "source": [
    "#####**4. Label Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "ftiigygFF1Gr",
    "outputId": "c8257f8f-1be3-4418-bec7-9b3409c3172f"
   },
   "outputs": [],
   "source": [
    "#CALCULATES total occurrence for each classes to check class imbalance\n",
    "class_counts = explore_df['label'].value_counts()\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.pie(class_counts, labels=class_counts.index, autopct='%1.1f%%', colors=['#FFD580','#FFFF99','#F08080'])\n",
    "plt.title('Citation Intent Class Distribution', fontsize=16, pad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYL3CduwF58n"
   },
   "source": [
    "Upon calculation results, we see that the classes are distributed unevenly in label columns indicating class imbalance where **background** label has **58.7%** dominance, followed by **method** with **27.8%** and **result** with just **13.5%** which may bias the model toward the majority class (i.e. Background)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZeasyclgG26Y"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DidC6VrpG4Fp"
   },
   "source": [
    "#####**5. Text Length Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWTNVemfG4__"
   },
   "outputs": [],
   "source": [
    "#FINDS the text length in string column for each row\n",
    "text_lengths = explore_df['string'].str.len()\n",
    "#GROUPS the extracted text length by label and calculates the average through mean()\n",
    "avg_length = text_lengths.groupby(explore_df['label']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "bzdaMZl1HVdo",
    "outputId": "851c3c49-8305-41c8-bcd4-13fdcca0709f"
   },
   "outputs": [],
   "source": [
    "#ROUNDS UP the value to 1\n",
    "avg_length.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duABwJesHa9A"
   },
   "source": [
    "**This check is done to ensure that differences in text length between classes do not unfairly influence the model performance. This ensures that the model should focus on semantic meaning rather than length.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjXCbolPHeyi"
   },
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLqvbIBeHhAQ"
   },
   "source": [
    "# **Feature Selection** üîé\n",
    "\n",
    "**Before training the model, it is essential to identify and retain only the most relevant features and target variables from the dataset. Since the focus of this project is text classification selection of only the column containing the citation sentences as the feature and the column containing the citation intent labels as the target.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "L3nPKNxQJSin",
    "outputId": "f45f6f45-935d-4819-cade-ecf459898259"
   },
   "outputs": [],
   "source": [
    "#PERFORM Feature Selection for explore_df by copying selected features into new dataframe\n",
    "findcite_df = explore_df[['string', 'label']].copy()\n",
    "findcite_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tb0EsFM6Mrmk"
   },
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptzIHttaKzAC"
   },
   "source": [
    "# **DATA SPLIT** üìë\n",
    "\n",
    "**The dataset is divided into training and test sets with 80-20 ratio. The training set is further partitioned to perform cross validation resulting in three distinct subsets: Train, Validation, and Test. This split ensures that the model can learn from the training data, tune hyperparameters using the validation set, and be evaluated on an unseen test set to provide an unbiased assessment of its performance. Stratification is applied during splitting to preserve the original class distribution across all subsets which is particularly important for multi-class classification tasks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUiz-SxjKUia"
   },
   "outputs": [],
   "source": [
    "#DEFINES X (Features) and y (Target)\n",
    "X = findcite_df['string']\n",
    "y = findcite_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M3d3QHc4MaP5"
   },
   "outputs": [],
   "source": [
    "#SPLITS train and tests with stratify\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzHYRWsvMoJF"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMPabb0fMeHp"
   },
   "source": [
    "# **Text Preprocessing** üî§\n",
    "\n",
    "1.   Tokenization\n",
    "2.   Text Removal (lower casing, punctuation removal, characters removal, space parsing removal, stopwords removal)\n",
    "3.   Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "plbVWf9qMqNw",
    "outputId": "38955257-dcaa-41a3-dfad-7998d5f8cd8f"
   },
   "outputs": [],
   "source": [
    "#DOWNLOADS NLTK resources required for text preprocessing\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-WBfCEXJOdFx"
   },
   "outputs": [],
   "source": [
    "#INITIALIZES the list of English stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bcF__l6LOg33"
   },
   "outputs": [],
   "source": [
    "#FUNCTION to preprocess string columns into cleaned texts for logistic regression model training\n",
    "def preprocess_text_for_logreg(text):\n",
    "\n",
    "    #TOKENIZES\n",
    "    words = text.split()\n",
    "\n",
    "    #REMOVES space sparse\n",
    "    cleaned_words = []\n",
    "    for word in words:\n",
    "        word = word.strip()\n",
    "        if word != '':\n",
    "            cleaned_words.append(word)\n",
    "\n",
    "    #CONVERTS to lowercase\n",
    "    lowercase_words = []\n",
    "    for word in cleaned_words:\n",
    "        lowercase_words.append(word.lower())\n",
    "\n",
    "    #REMOVES stopwords\n",
    "    filtered_words = []\n",
    "    for word in lowercase_words:\n",
    "        if word not in stop_words:\n",
    "            filtered_words.append(word)\n",
    "\n",
    "    #LEMMATIZES\n",
    "    lemmatized_words = []\n",
    "    for word in filtered_words:\n",
    "        lemma = lemmatizer.lemmatize(word)\n",
    "        lemmatized_words.append(lemma)\n",
    "\n",
    "    #STORES back to strings\n",
    "    cleaned_text = ' '.join(lemmatized_words)\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48AhmrboUFJL"
   },
   "outputs": [],
   "source": [
    "#APPLIES preprocessing function for logistic regression\n",
    "X_train_lr = X_train.apply(preprocess_text_for_logreg)\n",
    "X_test_lr  = X_test.apply(preprocess_text_for_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2qZxvmelU5eL"
   },
   "outputs": [],
   "source": [
    "#FUNCTION to preprocess string columns into cleaned texts for scibert model training\n",
    "def preprocess_text_for_scibert(text):\n",
    "\n",
    "    #REMOVES space sparse\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t0N4VCbtWNsT"
   },
   "outputs": [],
   "source": [
    "#APPLIES preprocessing function for scibert\n",
    "X_train_scibert = X_train.apply(preprocess_text_for_scibert)\n",
    "X_test_scibert  = X_test.apply(preprocess_text_for_scibert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TDhKVBwbgtr"
   },
   "source": [
    "**The data is preprocessed differently depending on the model. For Logistic Regression, the text is cleaned by removing extra spaces, lowercased, stopwords removed and lemmatized. For SciBERT, only leading and trailing spaces are removed since the model can handle raw scientific text on its own.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDLjyCwyxWm2"
   },
   "source": [
    "## **WORD CLOUDS** ‚òÅÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "MsG7C6KyxiFt",
    "outputId": "af617ac9-dd0b-48b8-c965-ef01d762983d"
   },
   "outputs": [],
   "source": [
    "#SHOWS word cloud for logistic regression\n",
    "plot_wordcloud_per_class(X_train_lr, y_train, title=\"Word Cloud for Logistic Regression:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "qF9taMZD9-mO",
    "outputId": "1a761f02-e8eb-430a-95eb-7e2d99afaf00"
   },
   "outputs": [],
   "source": [
    "#SHOWS word cloud for sciBERT\n",
    "plot_wordcloud_per_class(X_train_scibert, y_train, title=\"Word Cloud for SciBERT:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLtBqMDEWUqk"
   },
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPye6S8ebXqE"
   },
   "source": [
    "# **Target Preprocessing** üéØ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XSMcIVV_cn2w"
   },
   "outputs": [],
   "source": [
    "#CONVERTS labels into label numberings\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeMgU4-7dHeF"
   },
   "source": [
    "**It converts the labels (Target) into categorical encoding like 0, 1 and 2.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEN8mGjNcvhw"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSQ4YpwVdVd2"
   },
   "source": [
    "# **Model Training** ü§ñ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Erw5luldspn"
   },
   "source": [
    "**In this section, we train two different models to classify the citation intent to compare their performances. Apart from just performance comparison, experimental analysis through hyperparameter tuning on the baseline models is also done handling real-life scenarios and not just to focus on accuracy but identified class imbalances and future occuring overfits.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvcS2a29h5_J"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFPjSWIif9HA"
   },
   "source": [
    "#####**1. TF-IDF + Logistic Regression**\n",
    "\n",
    "**A multinomial Logistic Regression model (with Softmax activation) is then trained on the TF-IDF features to predict the probability of each citation intent class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TFawv4x6h5F6"
   },
   "outputs": [],
   "source": [
    "#CREATES pipeline to perform TF-IDF to only the preprocessed training set avoiding data leakage\n",
    "logreg_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "id": "m41r088wiCmL",
    "outputId": "a9162821-e5fa-48fd-9042-09701b7425c2"
   },
   "outputs": [],
   "source": [
    "#TRAINS the model using the pipeline\n",
    "logreg_pipeline.fit(X_train_lr, y_train_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "DIRAmflaofye",
    "outputId": "78a99a23-2da0-441a-987a-2c4d839174fd"
   },
   "outputs": [],
   "source": [
    "#SHOWS training and validation scores for baseline model training behavior\n",
    "plot_learning_curve(\n",
    "    logreg_pipeline,\n",
    "    X_train, y_train,\n",
    "    cv=5,\n",
    "    scoring='f1_macro',\n",
    "    title=\"Baseline Logistic Regression\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uuaAjYxjiG9a"
   },
   "outputs": [],
   "source": [
    "#PREDICTIONS of trained baseline model\n",
    "y_pred = logreg_pipeline.predict(X_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JWELXdaDiKlk",
    "outputId": "35be18b1-63c6-4754-c047-2bc75c09fb46"
   },
   "outputs": [],
   "source": [
    "#SHOWS classification report\n",
    "print(classification_report(y_test_enc, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "id": "Ki9FT0VSvje_",
    "outputId": "04618e0c-8cb5-4c9f-ad32-2bfce7a074cf"
   },
   "outputs": [],
   "source": [
    "#SHOWS confusion matrix\n",
    "plot_confusion_matrix(\n",
    "    y_test_enc,\n",
    "    y_pred,\n",
    "    labels=logreg_pipeline.classes_,\n",
    "    title=\"Baseline Logistic Regression Confusion Matrix\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06hrLHHokUQs"
   },
   "source": [
    "**For the baseline Logistic Regression model, we use a simple train/test split to evaluate performance using default settings. Here, we can see the baseline model performs exceptionally nice with macro F1-score of 76% and accuracy of 80%. However, the model shows a clear sign of overfitting with start off difference of approximately 25%. Also, the macro F1-score is basically influenced by the majority class whereas the recall performance for minority classes is not seen to be very good. Keeping these observations in mind, it is evident that while the baseline Logistic Regression gives a reasonable overall performance, issues such as overfitting and lower recall for minority classes need to be addressed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qVfBKA7GGu-"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXxha3YviNxX"
   },
   "source": [
    "#####**Hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnOIb9jQGFXd"
   },
   "source": [
    "The hyperparameter tuning techniques used in order to address the issue are:\n",
    "\n",
    "1. Grid Search cv üó≥Ô∏è\n",
    "2. Class weights ‚öñÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ucwwfI1GVrf"
   },
   "outputs": [],
   "source": [
    "#ADDS class weight = 'balanced' to address the minority classes and have a balanced result\n",
    "tuned_logreg_pipeline = Pipeline([\n",
    "  ('tfidf', TfidfVectorizer()),\n",
    "  ('clf', LogisticRegression(\n",
    "      max_iter=1000,\n",
    "      class_weight = 'balanced',\n",
    "      random_state=42\n",
    "  ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1jhQHsHHdic"
   },
   "outputs": [],
   "source": [
    "#INITIALIZES each fold has roughly the same class proportions as the whole dataset\n",
    "skf = StratifiedKFold(\n",
    "  n_splits=5,\n",
    "  shuffle=True,\n",
    "  random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xTUy5SzGIKnB"
   },
   "outputs": [],
   "source": [
    "#SELECTS appropriate candidates for the best grid search combination\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [3000, 4000, 6000],\n",
    "    'clf__C': [0.005, 0.01, 0.03, 0.05, 0.1],\n",
    "    'tfidf__ngram_range': [(1, 1),(1,2)],\n",
    "    'tfidf__min_df': [5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jAdc-y_tJYED"
   },
   "outputs": [],
   "source": [
    "#RETRIEVES scorings of F1-score since accuracy can be misleading\n",
    "scoring = {\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'f1_micro': 'f1_micro',\n",
    "    'f1_weighted': 'f1_weighted'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7g2XHhdJfLK"
   },
   "outputs": [],
   "source": [
    "#PERFORMS hyperparameter tuning using GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    tuned_logreg_pipeline,\n",
    "    param_grid,\n",
    "    cv=skf,\n",
    "    scoring=scoring,\n",
    "    refit='f1_macro',\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IuhtkDUgJhph",
    "outputId": "a7562a08-dba9-4a50-e314-1ce4ca47b20c"
   },
   "outputs": [],
   "source": [
    "#TRAINS and DISPLAYS the best hyperparameter combination and the best macro-F1 score achieved\n",
    "grid_search.fit(X_train_lr, y_train_enc)\n",
    "print(\"The best settings are:\", grid_search.best_params_)\n",
    "print(\"The best F1 Score reached:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "h_DyGtElqDKq",
    "outputId": "6e51a396-cf4e-4151-fa2a-a76cdbfde666"
   },
   "outputs": [],
   "source": [
    "#PLOTS top TF-IDF features\n",
    "feat = grid_search.best_estimator_.named_steps['tfidf'].get_feature_names_out()\n",
    "imp  = grid_search.best_estimator_.named_steps['clf'].coef_\n",
    "\n",
    "top = np.argsort(np.mean(np.abs(imp), axis=0))[-10:]\n",
    "\n",
    "plt.barh(feat[top], np.mean(np.abs(imp), axis=0)[top], color='plum')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "i5bc2RxtJmmN",
    "outputId": "182ee1bc-cea8-4a94-de8d-a13f205c0334"
   },
   "outputs": [],
   "source": [
    "#SHOWS training and validation scores for model training behavior\n",
    "plot_learning_curve(\n",
    "    model=grid_search.best_estimator_,\n",
    "    X=X_train_lr,\n",
    "    y=y_train_enc,\n",
    "    cv=5,\n",
    "    scoring='f1_macro',\n",
    "    title=\"Tuned Logistic Regression\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pzzWM5tXXLDF",
    "outputId": "35199f36-59e5-47d0-e19a-2a853b39f815"
   },
   "outputs": [],
   "source": [
    "#CHECKS model convergence\n",
    "grid_search.best_estimator_.named_steps['clf'].n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJejeUhofNGn"
   },
   "source": [
    "**The model has learned as much as it can from the training data since it converges at 24 steps.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ezrEhadgKidq"
   },
   "outputs": [],
   "source": [
    "#PREDICTS using the best estimator\n",
    "y_pred= grid_search.best_estimator_.predict(X_test_lr)\n",
    "y_proba = grid_search.best_estimator_.predict_proba(X_test_lr)\n",
    "confidence = np.max(y_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fm6hLZLHPeps",
    "outputId": "cbe7311d-27bd-4dc4-bef6-4d227be23dcd"
   },
   "outputs": [],
   "source": [
    "#SHOWS classification report\n",
    "print(classification_report(y_test_enc, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "id": "1xkSYEXyaBVn",
    "outputId": "8057395a-08e7-4d12-c878-6862cf37ed89"
   },
   "outputs": [],
   "source": [
    "#SHOWS confusion matrix\n",
    "plot_confusion_matrix(\n",
    "    y_test_enc,\n",
    "    y_pred,\n",
    "    labels=grid_search.best_estimator_.classes_,\n",
    "    title=\"Tuned Logistic Regression Confusion Matrix\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "dMo13jun-NCD",
    "outputId": "036f593a-b0ec-484b-eb29-5805cf531a0d"
   },
   "outputs": [],
   "source": [
    "#SHOWS the one vs rest ROC-AUC curve\n",
    "y_scores_lr = grid_search.best_estimator_.predict_proba(X_test_lr)\n",
    "plot_roc_auc_curve(y_test_enc, y_scores_lr, class_names=le.classes_, title=\"Tuned Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "RVXwzpZgoi9S",
    "outputId": "acb7b8e8-994f-4850-a018-37c7e4dae4c3"
   },
   "outputs": [],
   "source": [
    "#SHOWS the one vs rest PR curve\n",
    "y_scores_lr = grid_search.best_estimator_.predict_proba(X_test)\n",
    "plot_precision_recall_curve(y_test_enc, y_scores_lr, title=\"Tuned Logistic Regression Precision-Recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qL7VgSpfPhhe"
   },
   "source": [
    "**The training and validation scores are much closer together with only 4% gap. The validation score rises to approximately 0.75-0.79, converging more tightly with the training line. In addition, even though the accuracy has decreased from 80% to 79%, the F1-scores for each classes have increased. Since the data is imbalanced, the priority lies to macro f1-score more than accuracy.**\n",
    "\n",
    "**The baseline model was clearly showing signs of overfitting as training score reached to ~ 89% but the model achieved only 80% whereas on the hyperparameter tuned model the training score and test score was closer being 80% to 78%.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CSu63-8jcQv"
   },
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmQ9dAbfjWsL"
   },
   "source": [
    "**ADDITIONAL PERFORMANCE METRICS USING GRID SEARCH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "DilzKqoWdYn-",
    "outputId": "3cabfb35-a761-435b-c4e5-12655cabdc10"
   },
   "outputs": [],
   "source": [
    "#DISPLAYS best combination by ranks\n",
    "full_results = pd.DataFrame(grid_search.cv_results_)\n",
    "necessary_results = full_results[['params', 'mean_test_f1_macro', 'std_test_f1_macro', 'rank_test_f1_macro']]\n",
    "necessary_results.sort_values(by='rank_test_f1_macro').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aLlJTmmijPs0",
    "outputId": "43161833-b7ce-4c9f-ba4d-7ee016e3e247"
   },
   "outputs": [],
   "source": [
    "#DISPLAYS the selected best combination metrics by each folds (K=5)\n",
    "best_idx = grid_search.best_index_\n",
    "for i in range(5):\n",
    "    print(\n",
    "        f\"Fold {i+1} F1-macro:\",\n",
    "        grid_search.cv_results_[f'split{i}_test_f1_macro'][best_idx],\n",
    "        \" | F1-micro:\",\n",
    "        grid_search.cv_results_[f'split{i}_test_f1_micro'][best_idx],\n",
    "        \" | F1-weighted:\",\n",
    "        grid_search.cv_results_[f'split{i}_test_f1_weighted'][best_idx]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aS6VMllFktFB"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tJR2rIDrExG"
   },
   "source": [
    "#####**2. SciBERT**\n",
    "\n",
    "**SciBERT is atransformer-based language model specifically trained on scientific text. It captures contextual relationships and has own tokenizer unlike other traditional models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLuesAz6riQA"
   },
   "outputs": [],
   "source": [
    "#DEFINES the model in use\n",
    "scibert_model = \"allenai/scibert_scivocab_uncased\"\n",
    "num_labels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "9e9b5ddf1b414788b0f5e5fd610be29d",
      "2b3054c473fe441c8cd21d5a10333808",
      "7aeebd6f5c4742cb9e5aa965b1e8eb33",
      "803c55e978654915b4c419e8de3a248a",
      "924b77d241cf4284bed0c1b9b1208769",
      "78b12d234d3946e2bbbe8f18375bdd51",
      "b9ff063226704eaabcd83377a4369163",
      "72fd8ae0a59c4d71a92ce3c0f1fac3bc",
      "d31b96e2fbef4b73ab03ba978b5a5d67",
      "d64d38e5db954de8a9fedff16ab85dc3",
      "59c27ac5f3a444a6a68d9149de5209b6",
      "9cc88f2674c440bea94fbba9b9150108",
      "bf84e68b899e44ccae8d3ff84cfab892",
      "db99da226500408988452eb16e206fe3",
      "fda207c80a094a608aa8a44c87bce6c1",
      "06c91ebeea6d420ea5cac686715af035",
      "2c1de144d98a4ac48d779a31305df6a7",
      "98bf7925ec4f4a99bac5bfa86d510c6e",
      "1b795cfd32694a5a8b405ae1d69bd9d5",
      "7eab64cf9dca47bebb95a7b5ead158c3",
      "688515f382cb45febf58378186fca177",
      "2d1f7279cd624b4ab2a85618b35b3548"
     ]
    },
    "id": "0QNlUbt7vXEA",
    "outputId": "b267661a-369f-45be-ed51-9be15e194fae"
   },
   "outputs": [],
   "source": [
    "#LOADS tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(scibert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140,
     "referenced_widgets": [
      "46d84be94ef84c2ab6954bb0e1c46df9",
      "8cdacb44af084fd58ac8da2d3f412b46",
      "cc4b492419fd4a73bc164a76b008301b",
      "a6258acc21f04f319d31302ea5f333d6",
      "02d640efc90945d2a1e0658f254b2729",
      "85cdc51cf5c4449fb722852226e89e83",
      "48b8dbbe96e9425ca3f4e849ddd2f29e",
      "62fb606648f24fc4a80a916f9c7eacbf",
      "24e28b06db0f42db8a95818d00bbf410",
      "3df8e940ec3d48d0bba8c92ca0e7d215",
      "0c79c18ff34e454aae26df9e18577afc"
     ]
    },
    "id": "yX0RjvgQvZZT",
    "outputId": "f03f808e-ce35-4504-cfdb-46910179812b"
   },
   "outputs": [],
   "source": [
    "#scibert = TFAutoModelForSequenceClassification.from_pretrained(scibert_model, num_labels=num_labels, from_pt=True)\n",
    "scibert = TFAutoModelForSequenceClassification.from_pretrained(scibert_model, num_labels=num_labels, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXATCVS4G9bu"
   },
   "outputs": [],
   "source": [
    "#FREEZES all layers except for the classification\n",
    "for layer in scibert.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "scibert.classifier.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eiE3ilzC4hJB"
   },
   "outputs": [],
   "source": [
    "#COMPUTE class weights to handle class imbalance for scibert\n",
    "classes = np.unique(y_train_enc)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train_enc)\n",
    "class_weights_dict = dict(zip(classes, class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Hz3yPc7xHCy"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SStwdatvwvEC"
   },
   "source": [
    "#####**VALIDATION SPLIT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XelVecCPvcWV"
   },
   "outputs": [],
   "source": [
    "#SPLITS the training sets into another subset with validation set as 20% of it\n",
    "X_train_sub, X_val, y_train_sub, y_val = train_test_split(\n",
    "    X_train_scibert, y_train_enc,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_train_enc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yr7dCLaxxIwj",
    "outputId": "26aa9669-ee3c-4bba-e87c-bb2049596019"
   },
   "outputs": [],
   "source": [
    "#USES scibert's own tokenizer to encode the sets\n",
    "train_encodings = tokenizer(list(X_train_sub), truncation=True, padding=True, max_length=128, return_tensors='tf')\n",
    "val_encodings = tokenizer(list(X_val), truncation=True, padding=True, max_length=128, return_tensors='tf')\n",
    "test_encodings = tokenizer(list(X_test_scibert), truncation=True, padding=True, max_length=128, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ii8-tus8xct8"
   },
   "outputs": [],
   "source": [
    "#CONVERTS tokenized inputs into TensorFlow datasets and batch them for training, validation, and testing\n",
    "batch_size=8\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    y_train_sub\n",
    ")).shuffle(1000).batch(batch_size)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    y_val\n",
    ")).batch(batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    y_test_enc\n",
    ")).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pv9JzK4z28Yp"
   },
   "outputs": [],
   "source": [
    "#COMPILES the SciBERT model\n",
    "scibert.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hPrX86StKhub"
   },
   "outputs": [],
   "source": [
    "#CREATES an early stop to avoid overfitting over epochs (currently it is not used since epochs are properly training if needed add in history as a callbacks=[early_stop])\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=0,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQgqOhuj31g-",
    "outputId": "2944a7b9-3c04-49d4-863c-7773ef0cf1a1"
   },
   "outputs": [],
   "source": [
    "#TRAINS the SciBERT model\n",
    "history = scibert.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=5,\n",
    "    class_weight=class_weights_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qAdYQopPQ72V"
   },
   "source": [
    "**Stop training immediately when validation accuracy does not improve compared to the best seen so far.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "zA48l63nSOLP",
    "outputId": "7c5ceb1b-54c2-4845-bf9a-dd7ed3000b1b"
   },
   "outputs": [],
   "source": [
    "#SHOWS the fined tuned model training vs validation loss\n",
    "plot_history(history, title='SciBERT Training vs Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "0lc5Sr_oSa9G",
    "outputId": "e2c61821-06c3-483e-b024-3676ed44ef74"
   },
   "outputs": [],
   "source": [
    "#SHOWS the fined tuned model training vs validation accuracy\n",
    "plot_history(history, metric='accuracy', title='SciBERT Training vs Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ost3-7rdSsPJ",
    "outputId": "e0407c17-9a7f-485c-adbb-ea80d8ab801e"
   },
   "outputs": [],
   "source": [
    "#CHECKS test loss and accuracy\n",
    "test_loss, test_acc = scibert.evaluate(test_dataset)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PhcYz7hcTQmX",
    "outputId": "a6ee3e6c-4863-4b5e-8887-cee3674b13f7"
   },
   "outputs": [],
   "source": [
    "#GETS predicted class labels from model outputs\n",
    "predictions = scibert.predict(test_dataset)\n",
    "logits = predictions.logits\n",
    "pred_labels = tf.argmax(logits, axis=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1WD4ust-Thup",
    "outputId": "31e5c351-bdfe-47f0-e728-e8c7f287259e"
   },
   "outputs": [],
   "source": [
    "#SHOWS classification report for scibert\n",
    "print(classification_report(y_test_enc, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "id": "3cnQZRv7T1X8",
    "outputId": "b16a28fa-edae-4a36-f9cf-f222cfce4437"
   },
   "outputs": [],
   "source": [
    "#SHOWS confusion matrix for scibert\n",
    "plot_confusion_matrix(\n",
    "    y_true=y_test_enc,\n",
    "    y_pred=pred_labels,\n",
    "    labels=[0, 1, 2],\n",
    "    title=\"SciBERT Confusion Matrix\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "Wwthp6hHJE3z",
    "outputId": "f377bdd9-cfc5-4853-aba6-c52d4027551b"
   },
   "outputs": [],
   "source": [
    "#SHOWS the one vs rest PR curve\n",
    "all_logits = []\n",
    "for batch in test_dataset:\n",
    "    outputs = scibert(batch)\n",
    "    batch_logits = outputs[0]\n",
    "    all_logits.append(batch_logits)\n",
    "\n",
    "logits = tf.concat(all_logits, axis=0)\n",
    "y_scores_sci = softmax(logits, axis=1)\n",
    "plot_precision_recall_curve(y_test_enc, y_scores_sci, title=\"SciBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "_rSkeoEfbqm-",
    "outputId": "eaa3d83f-caa9-4bdd-b64d-af934a80d799"
   },
   "outputs": [],
   "source": [
    "#SHOWS the roc-auc curve for scibert\n",
    "plot_roc_auc_curve(y_test_enc, y_scores_sci, class_names=le.classes_, title=\"SciBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CXNSzijjblsH",
    "outputId": "04b74786-e821-4846-95fe-fc59c32d299b"
   },
   "outputs": [],
   "source": [
    "#GIVES model internal flow\n",
    "scibert.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hIstbh4onD9H"
   },
   "source": [
    "**The training and validation scores for both loss and accuracy is improving which means the model is generalizing after all layers except for classification layer was dropped out. In addition, even though the validation accuracy slightly fluctuated at mid-way, the F1-scores for each classes have increased and validation loss tends to decrease till the 5th epochs. Since the data is imbalanced, the priority lies to macro f1-score more than accuracy.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SX2rHqJSNzXU"
   },
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwYzpBa-_KjX"
   },
   "source": [
    "# **Model Difference Validity Check** üìù"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTLvaiJc_jg7"
   },
   "source": [
    "**McNemar Test is used to check whether the difference is statistically significant. The p-value evaluates the hypothesis.**\n",
    "</br>\n",
    "</br>\n",
    "**H‚ÇÄ: Any performance difference is due to chance.**</br>\n",
    "**H‚ÇÅ: The performance difference is statistically significant.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8NJjZC21CVP-",
    "outputId": "0837df1b-ace5-41d2-fc4e-bba1c757c5c3"
   },
   "outputs": [],
   "source": [
    "#COMPUTES p-value to validate the statement\n",
    "y_pred_scibert = []\n",
    "y_pred_logreg = grid_search.best_estimator_.predict(X_test)\n",
    "for i in range(0, len(X_test), 8):\n",
    "    batch = tokenizer(X_test[i:i+8].tolist(), padding=True, truncation=True, max_length=128, return_tensors=\"tf\")\n",
    "    logits = scibert(batch)['logits']\n",
    "    y_pred_scibert.extend(tf.argmax(logits, axis=1).numpy())\n",
    "\n",
    "a = ((y_pred_logreg == y_test_enc) & (y_pred_scibert == y_test_enc)).sum()\n",
    "b = ((y_pred_logreg == y_test_enc) & (y_pred_scibert != y_test_enc)).sum()\n",
    "c = ((y_pred_logreg != y_test_enc) & (y_pred_scibert == y_test_enc)).sum()\n",
    "d = ((y_pred_logreg != y_test_enc) & (y_pred_scibert != y_test_enc)).sum()\n",
    "\n",
    "table = [[a, b],\n",
    "         [c, d]]\n",
    "\n",
    "result = mcnemar(table, exact=True)\n",
    "print(\"p-value:\", result.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a41UEYyvsrAO"
   },
   "source": [
    "**Since p-value is less than 0.05, the test successfully rejects the null hypothesis. This means that the difference between the models is statistically significantly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qB8IcLRi_IQ5"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQWoQsPtN0dr"
   },
   "source": [
    "# **Model Download** üì©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "N_Z3QYQHL-4O",
    "outputId": "b11c398e-a693-4abe-c651-bf4c8de5bd69"
   },
   "outputs": [],
   "source": [
    "#SAVES the Logistic regression model\n",
    "joblib.dump(grid_search.best_estimator_, 'logreg_model.pkl')\n",
    "files.download('logreg_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "siTEzDEhNPXj",
    "outputId": "16060580-ed2f-419f-e658-d5012c0d65fe"
   },
   "outputs": [],
   "source": [
    "#SAVES the sciBERT model\n",
    "scibert.save_pretrained(\"scibert_model\")\n",
    "tokenizer.save_pretrained(\"scibert_model\")\n",
    "!zip -r scibert_model.zip scibert_model\n",
    "files.download(\"scibert_model.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyvgn3fZm2Nw"
   },
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pc7hanDU3Tz"
   },
   "source": [
    "# **Thank you!!!** üòä"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
